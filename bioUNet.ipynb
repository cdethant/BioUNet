{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torchvision import models\n","from torch.nn.functional import relu"]},{"cell_type":"markdown","metadata":{},"source":["Below is a simple UNet from documentation used for training segmentation of MRI:\n","\n","Work Cited: https://pytorch.org/hub/mateuszbuda_brain-segmentation-pytorch_unet/"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from collections import OrderedDict\n","\n","class UNet(nn.Module):\n","\n","    def __init__(self, in_channels=3, out_channels=1, init_features=32):\n","        super(UNet, self).__init__()\n","\n","        features = init_features\n","\n","        # ._block is defined below, shortening the need for repeating Conv, Norm, and Activation calls.\n","\n","        # Encoder Block\n","        self.encoder1 = UNet._block(in_channels, features, name=\"enc1\")\n","        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.encoder2 = UNet._block(features, features * 2, name=\"enc2\")\n","        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.encoder3 = UNet._block(features * 2, features * 4, name=\"enc3\")\n","        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.encoder4 = UNet._block(features * 4, features * 8, name=\"enc4\")\n","        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        # Bridge/Bottleneck\n","        self.bottleneck = UNet._block(features * 8, features * 16, name=\"bottleneck\")\n","\n","        # Decoder Layer\n","        self.upconv4 = nn.ConvTranspose2d(\n","            features * 16, features * 8, kernel_size=2, stride=2\n","        )\n","        self.decoder4 = UNet._block((features * 8) * 2, features * 8, name=\"dec4\")\n","        self.upconv3 = nn.ConvTranspose2d(\n","            features * 8, features * 4, kernel_size=2, stride=2\n","        )\n","        self.decoder3 = UNet._block((features * 4) * 2, features * 4, name=\"dec3\")\n","        self.upconv2 = nn.ConvTranspose2d(\n","            features * 4, features * 2, kernel_size=2, stride=2\n","        )\n","        self.decoder2 = UNet._block((features * 2) * 2, features * 2, name=\"dec2\")\n","        self.upconv1 = nn.ConvTranspose2d(\n","            features * 2, features, kernel_size=2, stride=2\n","        )\n","        self.decoder1 = UNet._block(features * 2, features, name=\"dec1\")\n","\n","        self.conv = nn.Conv2d(\n","            in_channels=features, out_channels=out_channels, kernel_size=1\n","        )\n","\n","    def forward(self, x):\n","        enc1 = self.encoder1(x)\n","        enc2 = self.encoder2(self.pool1(enc1))\n","        enc3 = self.encoder3(self.pool2(enc2))\n","        enc4 = self.encoder4(self.pool3(enc3))\n","\n","        bottleneck = self.bottleneck(self.pool4(enc4))\n","\n","        dec4 = self.upconv4(bottleneck)\n","        dec4 = torch.cat((dec4, enc4), dim=1)\n","        dec4 = self.decoder4(dec4)\n","        dec3 = self.upconv3(dec4)\n","        dec3 = torch.cat((dec3, enc3), dim=1)\n","        dec3 = self.decoder3(dec3)\n","        dec2 = self.upconv2(dec3)\n","        dec2 = torch.cat((dec2, enc2), dim=1)\n","        dec2 = self.decoder2(dec2)\n","        dec1 = self.upconv1(dec2)\n","        dec1 = torch.cat((dec1, enc1), dim=1)\n","        dec1 = self.decoder1(dec1)\n","        return torch.sigmoid(self.conv(dec1))\n","\n","    @staticmethod\n","    def _block(in_channels, features, name):\n","        return nn.Sequential(\n","            OrderedDict(\n","                [\n","                    (\n","                        name + \"conv1\",\n","                        nn.Conv2d(\n","                            in_channels=in_channels,\n","                            out_channels=features,\n","                            kernel_size=3,\n","                            padding=1,\n","                            bias=False,\n","                        ),\n","                    ),\n","                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n","                    (name + \"relu1\", nn.ReLU(inplace=True)),\n","                    (\n","                        name + \"conv2\",\n","                        nn.Conv2d(\n","                            in_channels=features,\n","                            out_channels=features,\n","                            kernel_size=3,\n","                            padding=1,\n","                            bias=False,\n","                        ),\n","                    ),\n","                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n","                    (name + \"relu2\", nn.ReLU(inplace=True)),\n","                ]\n","            )\n","        )"]},{"cell_type":"markdown","metadata":{},"source":["The above code is long and tedious for defining a UNet layer by layer; thus can be simplified into funtions below:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def conv_block(input, num_filters):\n","    s = nn.Conv2d(num_filters, kernel_size=3, padding = 1)(input)\n","    s = nn.BatchNorm2d(num_filters)\n","    s = nn.ReLU()(s)\n","\n","    s = nn.Conv2d(num_filters, kernel_size=3, padding = 1)(s)\n","    s = nn.BatchNorm2d(num_filters)\n","    s = nn.ReLU()(s)\n","\n","    return s\n","\n","def encoder_block(input, num_filters):\n","    s = conv_block(input, num_filters)\n","    p = nn.MaxPool2d(kernel_size=2, stride=2)(s)\n","\n","    return s, p\n","\n","def decoder_block(input, num_filters, skip_connections):\n","    d = nn.ConvTranspose2d(num_filters, kernel_size=2, stride=2)(input)\n","    d = torch.cat([d, skip_connections])\n","    d = conv_block(input, num_filters)\n","\n","    return d\n","\n","\n","def create_UNet(input_shape, n_classes):\n","    inputs = Input(input_shape)\n","\n","    s1, p1 = encoder_block(inputs, 64)\n","    s2, p2 = encoder_block(p1, 128)\n","    s3, p3 = encoder_block(p2, 256)\n","    s4, p4 = encoder_block(p3, 512)\n","\n","    b1 = conv_block(p4, 1024)\n","\n","    d1 = decoder_block(b1, 1024, s4)\n","    d2 = decoder_block(d1, 512, s3)\n","    d3 = decoder_block(d2, 256, s2)\n","    d4 = decoder_block(d3, 128, s1)\n","\n","    output = nn.Conv2d(64, n_classes, kernel_size=1)\n","\n","    model = \n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Dataset\n","class CustomImageDataset(Dataset):\n","    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n","        self.img_labels = pd.read_csv(annotations_file)\n","        self.img_dir = img_dir\n","        self.transform = transform\n","        self.target_transform = target_transform\n","\n","    def __len__(self):\n","        return len(self.img_labels)\n","\n","    def __getitem__(self, idx):\n","        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n","        image = read_image(img_path)\n","        label = self.img_labels.iloc[idx, 1]\n","        if self.transform:\n","            image = self.transform(image)\n","        if self.target_transform:\n","            label = self.target_transform(label)\n","        return image, label\n","\n","\n","\n","images = []\n","masks = []\n","\n","train_dataset = CustomImageDataset()\n","val_dataset = CustomImageDataset()\n","\n","# Dataloader\n","train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = 64)\n","val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size = 6)\n","\n","def train():\n","    model = create_UNet()\n","    optimizer = optim.Adam(model.parameters(), lr = 0.001)\n","    cec = nn.CrossEntropyLoss()\n","    accuracies = []\n","    max_accuracy = 0\n","\n","    device = next(model.parameters()).device\n","\n","    num_epochs = 10\n","\n","    for epoch in range(num_epochs):\n","        # Train Mode\n","        model.train()\n","\n","        for i, (images, labels) in enumerate(train_dataloader):\n","            images = images.to(device)\n","            labels = labels.to(device)\n","\n","            #No gradient descent\n","            optimizer.zero_grad()\n","\n","            #Calculate Loss\n","            pred = model(images)\n","            loss = cec(pred, labels)\n","\n","            #Backpropagation\n","            loss.backward()\n","\n","            #Adjust & optimize model parameters\n","            optimizer.step()\n","\n","\n","        model.eval()\n","        running_loss = 0.0\n","\n","        with torch.no_grad():\n","            for inputs, targets in val_dataloader:\n","                inputs, targets = inputs.cuda(), targets.cuda()\n","                outputs = model(inputs)\n","                loss = criterion(outputs, targets)\n","                running_loss += loss.item() * inputs.size(0)\n","                accuracy = \n","\n","        avg_loss = running_loss / len(dataloader.dataset)\n","        print(f'Validation Loss: {avg_loss:.4f}')\n","    \n","        accuracies.append(accuracy)\n","        \n","        # Find best model\n","        if (accuracy > max_accuracy):\n","            max_accuracy = accuracy\n","            best_model = copy.deepcopy(model)\n","            print(f'Epoch: {epoch + 1}, Accuracy: {accuracy}')\n","\n","\n","\n","\n","#Validation\n","def val_loop(model, data):\n","    model.eval() #switch from training to validation mode\n","    total = 0\n","    correct = 0\n","\n","    #Declaring the device\n","    device = next(model.parameters()).device\n","\n","    with torch.no_grad(): #No gradient descent needed\n","        for images, labels in data:\n","            #Puts each image on CUDA\n","            images = images.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(images)\n","\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","\n","    return 100 * correct / total"]}],"metadata":{"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":2}
